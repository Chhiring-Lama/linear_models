---
title: "Cross Validation"
author: "Chhiring Lama"
date: "2024-11-19"
output: github_document
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
library(SemiPar)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "85%", 
	fig.align = "center"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

Look at LIDAR data
```{r}
data("lidar")

lidar_df <- lidar |> 
  as_tibble() |> 
  mutate(id = row_number())
```

```{r}
lidar_df |> 
  ggplot(aes(x = range, y = logratio)) + 
  geom_point()
```

## Try to do CV

Compare 3 models = one Linear, one smooth and one wiggly

Construct training and testing datasets
```{r}
train_df <- sample_frac(
  lidar_df, 
  size = .8
)

test_df <- anti_join(lidar_df, train_df, by = "id")
```

Look at these
```{r}
train_df |> 
  ggplot(aes(x = range, y = logratio)) + 
  geom_point()+
  geom_point(data = test_df, color = "red")
```

Fit the 3 models
```{r}
linear_model = lm(logratio ~ range, data = train_df)
smooth_model = gam(logratio ~ s(range), data = train_df)
wiggly_model = gam(logratio ~ s(range, k = 30), data = train_df, sp = 10e-6)
```

Look at the fits
```{r}
train_df |> 
  add_predictions(linear_model) |> 
  ggplot(aes(x = range, y = logratio)) + 
  geom_point()+
  geom_line(aes(y = pred), color = "red") +
  geom_point(data = test_df, color = "red")+
  labs(title = "Linear Model fit")
```

```{r}
train_df |> 
  add_predictions(wiggly_model) |> 
  ggplot(aes(x = range, y = logratio)) + 
  geom_point()+
  geom_line(aes(y = pred), color = "red") +
  geom_point(data = test_df, color = "red")+
  labs(title = "Linear Model fit")
```

```{r}
train_df |> 
  add_predictions(smooth_model) |> 
  ggplot(aes(x = range, y = logratio)) + 
  geom_point()+
  geom_line(aes(y = pred), color = "red") +
  geom_point(data = test_df, color = "red")+
  labs(title = "Linear Model fit")
```

Compare them numerically using RMSE
```{r}
rmse(linear_model, test_df)
rmse(smooth_model, test_df)
rmse(wiggly_model, test_df)
```

Small difference between smooth and wiggly model. Will this be consistent if we use different training and testing data

## Repeat the train/test split
```{r}
cv_df <- crossv_mc(lidar_df, 100)

cv_df |>  
  pull(train) |>
  nth(3) |> 
  as_tibble()
```

```{r}
cv_res_df <- cv_df |> 
  mutate(
    linear_mod = map(train, \(x) lm(logratio ~ range, data = x)), 
    smooth_mod = map(train, \(x) gam(logratio ~ s(range), data = x)), 
    wiggly_mod = map(train, \(x) gam(logratio ~ s(range, k = 30), sp = 10e-6, data = x))
  ) |> 
  mutate(
    rmse_linear = map2_dbl(linear_mod, test, rmse), 
    rmse_smooth = map2_dbl(smooth_mod, test, rmse), 
    rmse_wiggly = map2_dbl(wiggly_mod, test, rmse)
  )
```

```{r}
cv_res_df |> 
  select(starts_with("rmse"))  |> 
  pivot_longer(
    everything(),
    names_to = "model_type", 
    values_to = "rmse"
  ) |> 
  ggplot(aes(x = model_type, y = rmse)) +
  geom_violin()
  
```

Smooth model has the least RMSE. So, this seems to be the best fit. 

## Example: Child Growth 

Import Nepalese children dataset
```{r}
child_df <- read_csv("data/nepalese_children.csv") |> 
  mutate(
    weight_ch7 = (weight > 7) * (weight - 7)
  )
```

Look at the data
```{r}
ggplot(child_df, aes(x = weight, y = armc)) +
  geom_point(alpha = 0.5)
```

Fit some models
```{r}
linear_model = lm(armc ~ weight, data = child_df)
pwl_model = lm(armc ~ weight + height, data = child_df)
smooth_model = gam(armc ~ s(weight), data = child_df)
```

```{r}
child_df |> 
  gather_predictions(linear_model, pwl_model, smooth_model) |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = weight, y = armc)) + 
  geom_point(alpha = .5) +
  geom_line(aes(y = pred), color = "red") + 
  facet_grid(~model)
```








